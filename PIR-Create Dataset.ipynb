{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For dataset, we consider Train, Validation and Test dataset. There are totally 24 classes been considered for this projecct. \n",
    "Eeach class in train set has 800 images, 320 images in test and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YMSURej2UH58"
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_folder(dataset_path, folders):\n",
    "    try:\n",
    "        for item in folders:\n",
    "          \n",
    "          if os.path.exists(dataset_path+item):\n",
    "                print(\"directory already exists.. skipping\")\n",
    "                continue\n",
    "                \n",
    "          print(\"Creating folder-%s in path-%s\"%(item,dataset_path ))\n",
    "          os.mkdir(dataset_path+item)\n",
    "\n",
    "    except OSError as e:\n",
    "        print(\"wrong directory\")\n",
    "       \n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n",
      "directory already exists.. skipping\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "train_path = 'C:/Users/Owner/Desktop/Produce Item Recognition/DataSet/TrainSet/'\n",
    "valid_path = 'C:/Users/Owner/Desktop/Produce Item Recognition/DataSet/ValidationSet/'\n",
    "test_path = 'C:/Users/Owner/Desktop/Produce Item Recognition/DataSet/TestSet/'\n",
    "\n",
    "folders=['Blueberry','Garlic','Yellow Potato','Spinach','Yellow Onion','Apple', 'Avocado', 'Banana', 'bell pepper','Cabbage','Brocolli', 'Canada Pear', 'Carrot', 'Green Peas', 'Green Pepper', 'Lettuce', 'Mangoes', 'Okra', 'Orange', 'Pineapple', 'Red Chilli', 'Red Onions', 'Spring Onion', 'Tomato']\n",
    "\n",
    "path=[train_path,valid_path,test_path]\n",
    "\n",
    "for dataset_path in path:\n",
    "    create_folder(dataset_path,folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert videos into images and copy it to respective dataset folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9973,
     "status": "ok",
     "timestamp": 1584610595788,
     "user": {
      "displayName": "dataScience Project",
      "photoUrl": "",
      "userId": "07599909461418126384"
     },
     "user_tz": 300
    },
    "id": "NZTQHib20OR4",
    "outputId": "cfc354fd-6263-4c9c-eda5-0386fddeaf14"
   },
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "def collect_frame(sec,destination,video_cap,image_name,count):\n",
    "   \n",
    "    video_cap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n",
    "    frames,image = video_cap.read()\n",
    "   \n",
    "    if frames:\n",
    "        cv2.imwrite(destination+image_name+str(count)+\".jpg\", image)   \n",
    "    return frames\n",
    "\n",
    "\n",
    "def video_to_image_convert(destination_path,source_path,folders,frame_rate,number_of_images,image_name):\n",
    "    \n",
    "  for item in folders:\n",
    "      \n",
    "      print(item)\n",
    "    \n",
    "      destination=destination_path+item+\"/\"\n",
    "      source=source_path+item+\".mp4\"\n",
    "      print( source)\n",
    "      print(destination)\n",
    "      \n",
    "      video_cap = cv2.VideoCapture(source)\n",
    "      sec = 0\n",
    "      frame_rate = frame_rate\n",
    "      count=1\n",
    "      success = collect_frame(sec,destination,video_cap,image_name,count)\n",
    "      while success:\n",
    "          if count<=number_of_images:\n",
    "            count = count + 1\n",
    "            sec = sec + frame_rate\n",
    "            sec = round(sec, 2)\n",
    "            success = collect_frame(sec,destination,video_cap,image_name,count)\n",
    "          else:\n",
    "            success=False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spinach\n",
      "C:/Users/Owner/Desktop/Produce Item Recognition/Fruits and Vegetables Videos/Spinach.mp4\n",
      "C:/Users/Owner/Desktop/Produce Item Recognition/DataSet/ValidationSet/Spinach/\n",
      "Apple\n",
      "C:/Users/Owner/Desktop/Produce Item Recognition/Fruits and Vegetables Videos/Apple.mp4\n",
      "C:/Users/Owner/Desktop/Produce Item Recognition/DataSet/ValidationSet/Apple/\n",
      "Pineapple\n",
      "C:/Users/Owner/Desktop/Produce Item Recognition/Fruits and Vegetables Videos/Pineapple.mp4\n",
      "C:/Users/Owner/Desktop/Produce Item Recognition/DataSet/ValidationSet/Pineapple/\n",
      "Carrot\n",
      "C:/Users/Owner/Desktop/Produce Item Recognition/Fruits and Vegetables Videos/Carrot.mp4\n",
      "C:/Users/Owner/Desktop/Produce Item Recognition/DataSet/ValidationSet/Carrot/\n",
      "Tomato\n",
      "C:/Users/Owner/Desktop/Produce Item Recognition/Fruits and Vegetables Videos/Tomato.mp4\n",
      "C:/Users/Owner/Desktop/Produce Item Recognition/DataSet/ValidationSet/Tomato/\n",
      "Orange\n",
      "C:/Users/Owner/Desktop/Produce Item Recognition/Fruits and Vegetables Videos/Orange.mp4\n",
      "C:/Users/Owner/Desktop/Produce Item Recognition/DataSet/ValidationSet/Orange/\n",
      "Brocolli\n",
      "C:/Users/Owner/Desktop/Produce Item Recognition/Fruits and Vegetables Videos/Brocolli.mp4\n",
      "C:/Users/Owner/Desktop/Produce Item Recognition/DataSet/ValidationSet/Brocolli/\n"
     ]
    }
   ],
   "source": [
    "source_path=\"C:/Users/Owner/Desktop/Produce Item Recognition/Fruits and Vegetables Videos/\"\n",
    "destination_path=valid_path\n",
    "frame_rate=0.12\n",
    "number_of_images=330\n",
    "image_name=\"valid_00_1\"\n",
    "folders=['Spinach','Apple','Pineapple','Carrot','Tomato','Orange','Brocolli']\n",
    "video_to_image_convert(destination_path,source_path,folders,frame_rate,number_of_images,image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset diversity increased here by taking internet images and augmenting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        #width_shift_range=0.5,\n",
    "        #height_shift_range=0.5,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        #vertical_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "img = load_img('C:/Users/Owner/Desktop/Produce Item Recognition/DataSet/TrainSet/Yellow Onion/4.jpg')  # this is a PIL image\n",
    "x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "\n",
    "# the .flow() command below generates batches of randomly transformed images\n",
    "# and saves the results to the `preview/` directory\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir='C:/Users/Owner/Desktop/Produce Item Recognition/DataSet/TrainSet/Yellow Onion/', save_prefix='trainaug', save_format='jpg'):\n",
    "    i += 1\n",
    "    if i > 60:\n",
    "        break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kukOkttT2Y0N"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "train_path = 'C:/Users/Owner/Desktop/Produce Item Recognition/DataSet/TrainSet/'\n",
    "valid_path = 'C:/Users/Owner/Desktop/Produce Item Recognition/DataSet/ValidationSet/'\n",
    "test_path = 'C:/Users/Owner/Desktop/Produce Item Recognition/DataSet/TestSet/'\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "folders = glob(train_path + '/*')\n",
    "for folder in folders:\n",
    "  number_of_images=glob(folder+'/*.jp*g')\n",
    "  if len(number_of_images)>800:\n",
    "     files = random.sample(number_of_images, len(number_of_images)-800)  # Pick  random images\n",
    "     for index in files:  # Go over each file name to be deleted\n",
    "        f = os.path.join(folder, index)  # delete extra images\n",
    "        os.remove(f) \n",
    "\n",
    "folders = glob(valid_path + '/*')\n",
    "for folder in folders:\n",
    "  number_of_images=glob(folder+'/*.jp*g')\n",
    "  if len(number_of_images)>320:\n",
    "     files = random.sample(number_of_images, len(number_of_images)-320)  # Pick  random images\n",
    "     for index in files:  # delete extra images\n",
    "        f = os.path.join(folder, index)  # Create valid path to file\n",
    "        os.remove(f) \n",
    "\n",
    "folders = glob(test_path + '/*')\n",
    "for folder in folders:\n",
    "  number_of_images=glob(folder+'/*.jp*g')\n",
    "  if len(number_of_images)>320:\n",
    "     files = random.sample(number_of_images, len(number_of_images)-320)  # Pick  random images\n",
    "     for index in files:  # delete extra images\n",
    "        f = os.path.join(folder, index)  # Create valid path to file\n",
    "        os.remove(f) \n",
    "\n",
    "image_files = glob(train_path + '/*/*.jp*g')\n",
    "valid_image_files = glob(valid_path + '/*/*.jp*g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 575,
     "status": "ok",
     "timestamp": 1584610613941,
     "user": {
      "displayName": "dataScience Project",
      "photoUrl": "",
      "userId": "07599909461418126384"
     },
     "user_tz": 300
    },
    "id": "EP6gZfVpeWgx",
    "outputId": "ae3f5c4e-b716-4687-eb5d-d97ce3813037"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Apple': 800, 'Avocado': 800, 'Banana': 800, 'bell pepper': 800, 'Blueberry': 795, 'Brocolli': 800, 'Cabbage': 800, 'Canada Pear': 796, 'Carrot': 800, 'Garlic': 796, 'Green Peas': 794, 'Green Pepper': 800, 'Lettuce': 800, 'Mangoes': 800, 'Okra': 800, 'Orange': 800, 'Pineapple': 800, 'Red Chilli': 800, 'Red Onions': 800, 'Spinach': 800, 'Spring Onion': 800, 'Tomato': 800, 'Yellow Onion': 800, 'Yellow Potato': 800}\n",
      "{'Apple': 320, 'Avocado': 320, 'Banana': 320, 'bell pepper': 320, 'Blueberry': 320, 'Brocolli': 320, 'Cabbage': 320, 'Canada Pear': 320, 'Carrot': 320, 'Garlic': 320, 'Green Peas': 320, 'Green Pepper': 320, 'Lettuce': 320, 'Mangoes': 320, 'Okra': 320, 'Orange': 320, 'Pineapple': 320, 'Red Chilli': 320, 'Red Onions': 320, 'Spinach': 320, 'Spring Onion': 320, 'Tomato': 320, 'Yellow Onion': 320, 'Yellow Potato': 320}\n",
      "{'Apple': 320, 'Avocado': 320, 'Banana': 320, 'bell pepper': 320, 'Blueberry': 320, 'Brocolli': 320, 'Cabbage': 320, 'Canada Pear': 320, 'Carrot': 320, 'Garlic': 320, 'Green Peas': 320, 'Green Pepper': 320, 'Lettuce': 320, 'Mangoes': 320, 'Okra': 320, 'Orange': 320, 'Pineapple': 320, 'Red Chilli': 320, 'Red Onions': 320, 'Spinach': 320, 'Spring Onion': 320, 'Tomato': 320, 'Yellow Onion': 320, 'Yellow Potato': 320}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os\n",
    "import random\n",
    "from glob import glob\n",
    "train_path = 'C:/Users/Owner/Desktop/Produce Item Recognition/DataSet/TrainSet/'\n",
    "valid_path = 'C:/Users/Owner/Desktop/Produce Item Recognition/DataSet/ValidationSet/'\n",
    "test_path = 'C:/Users/Owner/Desktop/Produce Item Recognition/DataSet/TestSet/'\n",
    "entries = os.listdir(train_path)\n",
    "folders = glob(train_path + '/*')\n",
    "train_class_dist={}\n",
    "count=0\n",
    "for folder in folders:\n",
    "  number_of_images=glob(folder+'/*.jp*g')\n",
    "  train_class_dist[entries[count]]=len(number_of_images)\n",
    "  count+=1\n",
    "print(train_class_dist)\n",
    "\n",
    "test_entries = os.listdir(test_path)\n",
    "test_folders = glob(valid_path + '/*')\n",
    "test_class_dist={}\n",
    "count=0\n",
    "for folder in test_folders:\n",
    "  test_number_of_images=glob(folder+'/*.jp*g')\n",
    "  test_class_dist[entries[count]]=len(test_number_of_images)\n",
    "  count+=1\n",
    "print(test_class_dist)\n",
    "\n",
    "valid_entries = os.listdir(valid_path)\n",
    "valid_folders = glob(valid_path + '/*')\n",
    "valid_class_dist={}\n",
    "count=0\n",
    "for folder in valid_folders:\n",
    "  valid_number_of_images=glob(folder+'/*.jp*g')\n",
    "  valid_class_dist[entries[count]]=len(valid_number_of_images)\n",
    "  count+=1\n",
    "print(valid_class_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOEBPGEbilH6VTVBWgTV3gp",
   "collapsed_sections": [],
   "mount_file_id": "1Vb8j0-i6hH1F7Ap5npXqrUKILQ_XIkT8",
   "name": "Create Dataset.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
